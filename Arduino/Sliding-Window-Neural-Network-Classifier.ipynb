{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Neural Network based Classifier with a Sliding Widnow Sampler for EM Traces\n",
    "\n",
    "This notebook introduces a software activity classifier of IoT devices through their EM emissions. The training phase of the neural network uses labeled Fourier Transforms of EM traces while the testing phase using a sliding window to sample new data from live EM data streams as testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM Trace Acquisition - (doesn't work temporarily)\n",
    "\n",
    "We use a client Shell script at the target device as a UDP client and the following python script as the UDP server at the host computer. The Client Shell script notify the beginning and ending of a specific software activity based on which the UDP server takes small EM trace files for each activity region. The following UDP server utilize a GNURadio Companion (GRC) scipt file named as **arduino-data-acquisition.grc** underneath by importing the **top_block.py** file which is generated by the GRC file initially.\n",
    "\n",
    "After a sufficient number of EM traces are saved, they should be manually copied in to the correct class directory in **./data/em-traces/**, where there's a directory for each class.\n",
    "\n",
    "### Doesn't work:\n",
    "We need GNURadio 3.8 to generate a Python3-supported \"to_block.py\" code. Currently I have GNURadio 3.7 and therefore it works only on Python2.\n",
    "\n",
    "### Solution:\n",
    "The same following code is saved as a separate file name \"em-trace-capture.py\". Run it on the terminal separately with Python2 as follows.\n",
    "\n",
    "**python2 em-trace-capture.py**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import top_block\n",
    "import time\n",
    "\n",
    "print(\"Creating top_block class...\")\n",
    "tb=top_block.top_block()\n",
    "\n",
    "print(\"Starting top_block...\")\n",
    "tb.start()\n",
    "print(\"Started...\")\n",
    "\n",
    "while True:\n",
    "    print(\"starting...\")\n",
    "    tb.set_trigger(1)\n",
    "    time.sleep(0.025)\n",
    "    tb.set_trigger(-1)     \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM Trace Pre-Processing\n",
    "\n",
    "In this stage, we take EM traces from every class and then extract a smaller segment from it which is then Fourier Transformed, averaged to a 500 element vector and normalized. Finally, this vector is saved as a numpy array (.npy) as a feature vector with the file name **\\[class_label\\].\\[sequence_number\\].npy** in order to be used for training a classifier later. Following code should be run each time to create the training samples of a particular class by uncommenting the label of the class from the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a6dd69a3f087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# the directory from where the EM traces are taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mpath_to_em_traces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/em-traces/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m# the directory to store the training samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mpath_to_training_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/training-samples\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label' is not defined"
     ]
    }
   ],
   "source": [
    "import seciqlib as iq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Uncomment the correct label in order to generate the training data of that class\n",
    "#label='loop1' \n",
    "#label='loop2'\n",
    "#label='loop3'\n",
    "#label='loop4'\n",
    "#label='loop5'\n",
    "#label='loop6'\n",
    "#label='loop7'\n",
    "#label='loop8'\n",
    "#label='loop9'\n",
    "#label='loop10'\n",
    "\n",
    "# the position in the EM traces from which we take a little segment\n",
    "offset_time = 0\n",
    "window_time = 0.01\n",
    "\n",
    "# the directory from where the EM traces are taken\n",
    "path_to_em_traces = \"./data/em-traces/\"+label\n",
    "# the directory to store the training samples\n",
    "path_to_training_samples = \"./data/training-samples\"\n",
    "    \n",
    "listOfFiles = os.listdir(path_to_em_traces)\n",
    "traceCounter = 0\n",
    "\n",
    "for file_name in listOfFiles:\n",
    "    segment = iq.getSegmentData(path_to_em_traces+\"/\"+file_name, offset_time, window_time)\n",
    "    feature_vector = iq.getFeatureVector(segment)\n",
    "    #plt.figure()\n",
    "    #plt.plot(feature_vector)\n",
    "    #plt.show()    \n",
    "    np.save(path_to_training_samples+\"/\"+label+\".\"+str(traceCounter), feature_vector)  \n",
    "    traceCounter = traceCounter + 1\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing the Classifier\n",
    "\n",
    "All the training samples are read from the files and loaded into a 2-d array and fed into the Neural Network-based classifier. A simple train and test operation or a 10-fold cross-validation can be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[156   0   0   0   0   0   1   0   0   0]\n",
      " [  0 144   0   0   1   0   0   0   0   0]\n",
      " [  0   0 120   0   0   1  11   0   0   4]\n",
      " [  0   0   0 153   1   0   1   0   0   0]\n",
      " [  0   0   0   0 135   0   1   0   0   0]\n",
      " [  0   0   0   2   1 149   0   0   0   0]\n",
      " [  0   0   5   0   0   0 108   3   0  37]\n",
      " [  0   0   0   0   0   0   1 159   0   0]\n",
      " [  0   0   0   0   0   0   0   0 167   0]\n",
      " [  0   0   1   0   0   0  32   1   0 105]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      loop1       1.00      0.99      1.00       157\n",
      "     loop10       1.00      0.99      1.00       145\n",
      "      loop2       0.95      0.88      0.92       136\n",
      "      loop3       0.99      0.99      0.99       155\n",
      "      loop4       0.98      0.99      0.99       136\n",
      "      loop5       0.99      0.98      0.99       152\n",
      "      loop6       0.70      0.71      0.70       153\n",
      "      loop7       0.98      0.99      0.98       160\n",
      "      loop8       1.00      1.00      1.00       167\n",
      "      loop9       0.72      0.76      0.74       139\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nnclassifier as nn\n",
    "\n",
    "# the directory to store the training samples\n",
    "path_to_training_samples = \"./data/training-samples\"\n",
    "\n",
    "# loading the training samples to memory\n",
    "X, Y = nn.loadDataToXY(path_to_training_samples)\n",
    "\n",
    "# creating classifier\n",
    "clf = nn.createClassifier()\n",
    "\n",
    "# 10-fold cross-validation\n",
    "#nn.tenFoldCrossValidation(clf, X, Y)\n",
    "\n",
    "# Training and testing\n",
    "nn.trainAndTest(clf, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the trained model into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10-class-neural-network-model-joblib.model']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Saving the trained model to a file\n",
    "dump(clf, \"10-class-neural-network-model-joblib.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Classifier with Sliding Window Data - Stopped here\n",
    "\n",
    "The trained classifier is used in order to test a new and longer EM trace which can contain any unknown software activity related information. A sliding window is used to extract segments of data from the EM trace which are fed to the classifier to detect the software activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seciqlib as iq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# the initial position in the EM trace segment\n",
    "offset_time = 0\n",
    "window_time = 0.01\n",
    "\n",
    "'''\n",
    "label='3des'\n",
    "# the directory from where the EM traces are taken\n",
    "path_to_em_traces = \"./data/em-traces/\"+label\n",
    "# testing EM trace name\n",
    "file_name='file16_136_244.44975915.dat'\n",
    "'''\n",
    "\n",
    "label='loop1'\n",
    "# the directory from where the EM traces are taken\n",
    "path_to_em_traces = \"./data/sliding-window-traces/\"+label\n",
    "# testing EM trace name\n",
    "file_name='file16_102_134.48857225.dat'\n",
    "\n",
    "duration = iq.getTimeDuration(path_to_em_traces+'/'+file_name)\n",
    "\n",
    "while (offset_time + window_time) < duration:\n",
    "    print(offset_time)\n",
    "    segment = iq.getSegmentData(path_to_em_traces+\"/\"+file_name, offset_time, window_time)\n",
    "    feature_vector = iq.getFeatureVector(segment)\n",
    "    y_pred = nn.predictClass(clf, [feature_vector.tolist()])\n",
    "    print(y_pred)\n",
    "    offset_time = offset_time + 0.001\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
